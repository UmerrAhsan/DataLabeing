{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of gold_data is (866, 3)\n",
            "Shape of ws_train_data is (82, 3)\n",
            "Duplicate uuids count: 11\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np  \n",
        "gold_data = pd.read_csv('gold_train_data_entitywise.csv')\n",
        "print(f'Shape of gold_data is {gold_data.shape}')\n",
        "ws_data = pd.read_csv('llm_generated_output_in_entity_type_format.csv')\n",
        "# Drop rows where 'entity_text' column is null\n",
        "ws_data = ws_data.dropna(subset=['entity_text'])\n",
        "print(f'Shape of ws_train_data is {ws_data.shape}')\n",
        "# find the duplicate uuids count in ws_data and gold_data, means those uuids exists in both gold_data and ws_data and save it in duplicate_uuids_count\n",
        "duplicate_uuids_count = len(set(ws_data['uuid']).intersection(set(gold_data['uuid'])))\n",
        "print(f'Duplicate uuids count: {duplicate_uuids_count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A. Analysis on labeled Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. No of unique samples to be labeled:   306\n",
        "Because this is equal to input size. Also can be calculated/verified form the sentence level group by output that can be calculated using uuid\n",
        "n unique becasue in our input we assigned unique id to each sentence/sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique uuids in gold_data is 306\n"
          ]
        }
      ],
      "source": [
        "total_data_to_label = gold_data.uuid.nunique()\n",
        "print(f'unique uuids in gold_data is {total_data_to_label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open a file for writing\n",
        "with open('EvaluationResult.txt', 'w') as file:\n",
        "    # Write content to the file\n",
        "    file.write(f'unique uuids in gold_data is {total_data_to_label}\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Total no of unique samples labeled as non-zero by ws (Any ws_entity_type assigned other than 0):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total data labeled means any non-zero ws_entity_type assigned: 11\n"
          ]
        }
      ],
      "source": [
        "# find the no of unique sentences in df where ws_entity_type is not equal to 0. It means that sentence has atleast one entity\n",
        "data_labeled_by_ws = ws_data['uuid'].nunique()\n",
        "print(f'Total data labeled means any non-zero ws_entity_type assigned: {data_labeled_by_ws}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open a file for appending\n",
        "with open('EvaluationResult.txt', 'a') as file:\n",
        "    # Append content to the file\n",
        "    file.write(f'Total data labeled means any non-zero ws_entity_type assigned: {data_labeled_by_ws}\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Entity wise no of samples to be labeled. (e.g, where gt_entity_type = 1|2|3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "entity wise count in gold_data is \n",
            "gt_entity_type\n",
            "1    306\n",
            "2    306\n",
            "3    254\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# total number of unique sentences that were expected to be labeled as Document Name entity\n",
        "print(f'entity wise count in gold_data is \\n{gold_data.gt_entity_type.value_counts()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Entity wise total unique sentences labeled by WS. (e.g, where ws_entity_type = 1|2|3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled data ws_entity_type value counts: \n",
            "entity_type\n",
            "2    27\n",
            "1    11\n",
            "4    11\n",
            "5    11\n",
            "6    11\n",
            "3    11\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# show now the value counts of ws_entity_type in labeled_data\n",
        "print(f'Labeled data ws_entity_type value counts: \\n{ws_data.entity_type.value_counts()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Entity wise total samples correctly labeled by weak supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aggregate the data on the basis of uuid and ws_entity_type \n",
        "ws_train_data_agg = ws_data.groupby(['uuid','entity_type']).agg({\n",
        "    'entity_text': lambda x: ' '.join(x), \n",
        "}).reset_index()\n",
        "gold_data_agg = gold_data.groupby(['uuid','gt_entity_type']).agg({\n",
        "    'gt_entity_text': lambda x: ' '.join(x), \n",
        "}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ws_train_data_agg unique samples values counts: \n",
            "entity_type\n",
            "1    11\n",
            "2    11\n",
            "3    11\n",
            "4    11\n",
            "5    11\n",
            "6    11\n",
            "Name: count, dtype: int64\n",
            "gold_data_agg unique samples values counts: \n",
            "gt_entity_type\n",
            "1    306\n",
            "2    306\n",
            "3    254\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# print unique samples values counts in ws_train_data_agg \n",
        "print(f'ws_train_data_agg unique samples values counts: \\n{ws_train_data_agg.entity_type.value_counts()}')\n",
        "# also print for gold data\n",
        "print(f'gold_data_agg unique samples values counts: \\n{gold_data_agg.gt_entity_type.value_counts()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No of correct document name entities extracted by ws: 11\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Filter the ws_data_agg for class 1\n",
        "correct_doc_name_entity = ws_train_data_agg[\n",
        "    (ws_train_data_agg['entity_type'] == 1) & (ws_train_data_agg['uuid'].isin(gold_data_agg['uuid']))]\n",
        "\n",
        "# Merge correct_doc_name_entity with gold_data_agg on uuid and select desired columns\n",
        "correct_doc_name_entity = correct_doc_name_entity.merge(gold_data_agg[['uuid','gt_entity_type', 'gt_entity_text']], on='uuid', how='left')\n",
        "\n",
        "# Filter for class 1 again to ensure only relevant data is included\n",
        "correct_doc_name_entity = correct_doc_name_entity[(correct_doc_name_entity['entity_type'] == 1)\n",
        "                                                  & (correct_doc_name_entity['gt_entity_type'] == 1)]\n",
        "\n",
        "# Select the desired columns\n",
        "correct_doc_name_entity = correct_doc_name_entity[['uuid', 'entity_type', 'entity_text', 'gt_entity_type', 'gt_entity_text']]\n",
        "print(f'No of correct document name entities extracted by ws: {correct_doc_name_entity.shape[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No of correct party name entities extracted by ws: 11\n"
          ]
        }
      ],
      "source": [
        "# Filter the ws_data_agg for class 2\n",
        "correct_party_name_entity = ws_train_data_agg[\n",
        "    (ws_train_data_agg['entity_type'] == 2) & (ws_train_data_agg['uuid'].isin(gold_data_agg['uuid']))]\n",
        "\n",
        "# Merge correct_party_name_entity with gold_data_agg on uuid and select desired columns\n",
        "correct_party_name_entity = correct_party_name_entity.merge(gold_data_agg[['uuid','gt_entity_type', 'gt_entity_text']], on='uuid', how='left')\n",
        "\n",
        "# Filter for class 2 again to ensure only relevant data is included\n",
        "correct_party_name_entity = correct_party_name_entity[(correct_party_name_entity['entity_type'] == 2)\n",
        "                                                  & (correct_party_name_entity['gt_entity_type'] == 2)]\n",
        "\n",
        "# Select the desired columns\n",
        "correct_party_name_entity = correct_party_name_entity[['uuid', 'entity_type', 'entity_text', 'gt_entity_type', 'gt_entity_text']]\n",
        "print(f'No of correct party name entities extracted by ws: {correct_party_name_entity.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No of correct government law entities extracted by ws: 11\n"
          ]
        }
      ],
      "source": [
        "# Filter the ws_data_agg for class 3\n",
        "correct_gov_law_entity = ws_train_data_agg[\n",
        "    (ws_train_data_agg['entity_type'] == 3) & (ws_train_data_agg['uuid'].isin(gold_data_agg['uuid']))]\n",
        "\n",
        "# Merge correct_gov_law_entity with gold_data_agg on uuid and select desired columns\n",
        "correct_gov_law_entity = correct_gov_law_entity.merge(gold_data_agg[['uuid','gt_entity_type', 'gt_entity_text']], on='uuid', how='left')\n",
        "\n",
        "# Filter for class 3 again to ensure only relevant data is included\n",
        "correct_gov_law_entity = correct_gov_law_entity[(correct_gov_law_entity['entity_type'] == 3)\n",
        "                                                  & (correct_gov_law_entity['gt_entity_type'] == 3)]\n",
        "\n",
        "# Select the desired columns\n",
        "correct_gov_law_entity = correct_gov_law_entity[['uuid', 'entity_type', 'entity_text', 'gt_entity_type', 'gt_entity_text']]\n",
        "print(f'No of correct government law entities extracted by ws: {correct_gov_law_entity.shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unique text samples that are correctly labeled by ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No of correct labeled doc name entity: 11\n",
            "No of correct labeled party name entity: 11\n",
            "No of correct labeled gov law entity: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9012\\1576598440.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  unique_correct_doc_name_entity = ws_train_data_agg[(ws_train_data_agg['entity_type'] == 1)\n",
            "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9012\\1576598440.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  unique_correct_party_name_entity = ws_train_data_agg[(ws_train_data_agg['entity_type'] == 2)\n",
            "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9012\\1576598440.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  unique_correct_gov_law_entity = ws_train_data_agg[(ws_train_data_agg['entity_type'] == 3)\n"
          ]
        }
      ],
      "source": [
        "# Filter the ws_data_agg for class 1\n",
        "unique_correct_doc_name_entity = ws_train_data_agg[(ws_train_data_agg['entity_type'] == 1) \n",
        "                                       & (ws_train_data_agg['uuid'].isin(gold_data_agg['uuid']))\n",
        "                                       & (gold_data_agg['gt_entity_type'] == 1)]\n",
        "print(f'No of correct labeled doc name entity: {correct_doc_name_entity.shape[0]}')\n",
        "unique_correct_party_name_entity = ws_train_data_agg[(ws_train_data_agg['entity_type'] == 2) \n",
        "                                       & (ws_train_data_agg['uuid'].isin(gold_data_agg['uuid']))\n",
        "                                       & (gold_data_agg['gt_entity_type'] == 2)]\n",
        "print(f'No of correct labeled party name entity: {correct_party_name_entity.shape[0]}')\n",
        "unique_correct_gov_law_entity = ws_train_data_agg[(ws_train_data_agg['entity_type'] == 3) \n",
        "                                       & (ws_train_data_agg['uuid'].isin(gold_data_agg['uuid']))\n",
        "                                       & (gold_data_agg['gt_entity_type'] == 3)]\n",
        "print(f'No of correct labeled gov law entity: {correct_gov_law_entity.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>entity_type</th>\n",
              "      <th>entity_text</th>\n",
              "      <th>gt_entity_type</th>\n",
              "      <th>gt_entity_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0facc77f-1d2a-4645-92d8-5abb5f88b6ce</td>\n",
              "      <td>1</td>\n",
              "      <td>CO-BRANDING AGREEMENT</td>\n",
              "      <td>1</td>\n",
              "      <td>CO-BRANDING AGREEMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17af879e-9455-4dbc-b2bc-b2b1b849e805</td>\n",
              "      <td>1</td>\n",
              "      <td>VIDEO-ON-DEMAND CONTENT LICENSE AGREEMENT</td>\n",
              "      <td>1</td>\n",
              "      <td>VIDEO-ON-DEMAND CONTENT LICENSE AGREEMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1bdc2e9d-4ce6-4614-afc2-a568a7a1d167</td>\n",
              "      <td>1</td>\n",
              "      <td>JOINT DEVELOPMENT AGREEMENT</td>\n",
              "      <td>1</td>\n",
              "      <td>JOINT DEVELOPMENT AGREEMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>202e98a5-2b2c-48ed-ae9f-b9a27dedf809</td>\n",
              "      <td>1</td>\n",
              "      <td>e-business Hosting Agreement IBM</td>\n",
              "      <td>1</td>\n",
              "      <td>e-business Hosting Agreement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>451238df-68cc-476e-9e0a-9182e44cdc60</td>\n",
              "      <td>1</td>\n",
              "      <td>ENDORSEMENT AGREEMENT</td>\n",
              "      <td>1</td>\n",
              "      <td>ENDORSEMENT AGREEMENT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    uuid  entity_type  \\\n",
              "0   0facc77f-1d2a-4645-92d8-5abb5f88b6ce            1   \n",
              "3   17af879e-9455-4dbc-b2bc-b2b1b849e805            1   \n",
              "6   1bdc2e9d-4ce6-4614-afc2-a568a7a1d167            1   \n",
              "9   202e98a5-2b2c-48ed-ae9f-b9a27dedf809            1   \n",
              "12  451238df-68cc-476e-9e0a-9182e44cdc60            1   \n",
              "\n",
              "                                  entity_text  gt_entity_type  \\\n",
              "0                       CO-BRANDING AGREEMENT               1   \n",
              "3   VIDEO-ON-DEMAND CONTENT LICENSE AGREEMENT               1   \n",
              "6                 JOINT DEVELOPMENT AGREEMENT               1   \n",
              "9            e-business Hosting Agreement IBM               1   \n",
              "12                      ENDORSEMENT AGREEMENT               1   \n",
              "\n",
              "                               gt_entity_text  \n",
              "0                       CO-BRANDING AGREEMENT  \n",
              "3   VIDEO-ON-DEMAND CONTENT LICENSE AGREEMENT  \n",
              "6                 JOINT DEVELOPMENT AGREEMENT  \n",
              "9                e-business Hosting Agreement  \n",
              "12                      ENDORSEMENT AGREEMENT  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter the ws_data_agg for class 1\n",
        "correct_doc_name_entity.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. Evaluation on Correctly Labeled Data\n",
        "How much text of entities correctly predicted? Similarity score calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import spacy\n",
        "\n",
        "# create a class for similarity score calculation using tfidf and using embedding\n",
        "class similarity_evaluation:\n",
        "  def __init__(self):\n",
        "    self.tfidf_vectorizer = TfidfVectorizer()\n",
        "    # Load the spaCy model with word vectors (e.g., 'en_core_web_sm')\n",
        "    self.nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "  def calculate_TfIdf(self, string1,string2):\n",
        "    # Fit and transform the vectorizer on the two strings\n",
        "    tfidf_matrix = self.tfidf_vectorizer.fit_transform([string1, string2])\n",
        "    # Calculate the cosine similarity between the two vectors\n",
        "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "    # The similarity score is in cosine_sim[0][1]\n",
        "    similarity = cosine_sim[0][1]\n",
        "    return similarity\n",
        "\n",
        "  def similarity_evaluation_using_tfidf(self, df):\n",
        "    # receive the dataframe and find similarity between ws_entity_text and gt_entity_text and create a new column of similarity score and append it to the dataframe\n",
        "    # and store the similarity score of each sample in that column and return the updated dataframe\n",
        "    tfidf_similarity_score = []\n",
        "    for index, row in df.iterrows():\n",
        "      tfidf_similarity_score.append(self.calculate_TfIdf(row['entity_text'], row['gt_entity_text']))\n",
        "    df['tfidf_similarity_score'] = tfidf_similarity_score\n",
        "    return df\n",
        "  \n",
        "  def similarity_evaluation_using_spacy_embedding(self, df):\n",
        "    # receive the dataframe and find similarity between ws_entity_text and gt_entity_text and create a new column of similarity score and append it to the dataframe\n",
        "    # and store the similarity score of each sample in that column and return the updated dataframe\n",
        "    spacy_similarity_score = []\n",
        "    for index, row in df.iterrows():\n",
        "      spacy_similarity_score.append(self.nlp(row['entity_text']).similarity(self.nlp(row['gt_entity_text'])))\n",
        "    df['embedding_similarity_score'] = spacy_similarity_score\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entities Text Evaluation using Tf-Idf Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity percentage of document_name entity text extracted and actual: 0.9796831391340469\n",
            "Similarity percentage of parties entity text extracted and actual: 0.7647441771407664\n",
            "Similarity percentage of governing law entity text extracted and actual: 0.9617944246852423\n"
          ]
        }
      ],
      "source": [
        "evaluate_similarity = similarity_evaluation()\n",
        "# find similarity of document name entity text extracted and actual\n",
        "document_name_df_tfidf = evaluate_similarity.similarity_evaluation_using_tfidf(correct_doc_name_entity)\n",
        "# now find the mean of similarity score column \n",
        "print(\"Similarity percentage of document_name entity text extracted and actual:\", document_name_df_tfidf['tfidf_similarity_score'].mean())\n",
        "# save this to a csv file document_name_df\n",
        "# document_name_df.to_csv('../output/evaluation results/document_name_results.csv', index=False)\n",
        "party_name_df_tfidf = evaluate_similarity.similarity_evaluation_using_tfidf(correct_party_name_entity)\n",
        "print(\"Similarity percentage of parties entity text extracted and actual:\", party_name_df_tfidf['tfidf_similarity_score'].mean())\n",
        "# save this to a csv file party_name_df\n",
        "# party_name_df.to_csv('../output/evaluation results/party_name_results.csv', index=False)\n",
        "governing_law_df_tfidf = evaluate_similarity.similarity_evaluation_using_tfidf(correct_gov_law_entity)\n",
        "print(\"Similarity percentage of governing law entity text extracted and actual:\", governing_law_df_tfidf['tfidf_similarity_score'].mean())\n",
        "# save this to a csv file governing_law_df\n",
        "# governing_law_df.to_csv('../output/evaluation results/governing_law_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entities text evaluation using Spacy Embedding Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity percentage of document_name entity text extracted and actual: 0.9966746763159936\n",
            "Similarity percentage of parties entity text extracted and actual: 0.61252659546404\n",
            "Similarity percentage of governing law entity text extracted and actual: 0.9780230927824337\n"
          ]
        }
      ],
      "source": [
        "# find similarity of document name entity text extracted and actual using spacy embeddings\n",
        "document_name_df = evaluate_similarity.similarity_evaluation_using_spacy_embedding(correct_doc_name_entity)\n",
        "# now find the mean of similarity score column\n",
        "print(\"Similarity percentage of document_name entity text extracted and actual:\", document_name_df['embedding_similarity_score'].mean())\n",
        "# save this to a csv file document_name_df\n",
        "# document_name_df.to_csv('../output/evaluation results/document_name_results.csv', index=False)\n",
        "party_name_df = evaluate_similarity.similarity_evaluation_using_spacy_embedding(correct_party_name_entity)\n",
        "print(\"Similarity percentage of parties entity text extracted and actual:\", party_name_df['embedding_similarity_score'].mean())\n",
        "# save this to a csv file party_name_df\n",
        "# party_name_df.to_csv('../output/evaluation results/party_name_results.csv', index=False)\n",
        "governing_law_df = evaluate_similarity.similarity_evaluation_using_spacy_embedding(correct_gov_law_entity)\n",
        "print(\"Similarity percentage of governing law entity text extracted and actual:\", governing_law_df['embedding_similarity_score'].mean())\n",
        "# save this to a csv file governing_law_df\n",
        "# governing_law_df.to_csv('../output/evaluation results/governing_law_results.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FwT4KfmmSrTE",
        "IkSbU3IKS9iE",
        "7PgEq4bifSgs",
        "KPG3y0UTlE1e",
        "6ZRXAT6ksK3c",
        "eoknTuOowxjG",
        "64vvl7wi9H2r"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
